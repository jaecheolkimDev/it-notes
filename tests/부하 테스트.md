부하 테스트
==============

1\. 트래픽 증가에 따른 시스템 설계 및 확장 방법
-------------------------------------
1. 가장 간단한 형태
  - 구성 : EC2 서버 한 대에 프론트엔드, 백엔드, 데이터베이스에 관련된 프로그램을 다 실행시키는 형태의 구성이다.     
  이 형태의 장점은 하나의 서버에서 모든 리소스를 관리하기 때문에 관리 및 조작하기가 심플하다. 또한 다양한 리소스를 쓰지 않기 때문에 비용이 적게 나옴.
  - 문제점 : 하지만 실제 서비스를 운영하다보면 DB가 생각보다 많은 컴퓨팅 자원(CPU, 메모리, 디스크)을 사용한다.
  - 개선 : DB로 인해 웹 애플리케이션의 성능에 악영향을 줄 수 있기 때문에 별도의 서버를 분리하는 형식을 많이 가져간다.
2. DB 분리
  - 문제점 : 트래픽이 많아지면 정적 파일(이미지, 비디오, 웹 페이지 등)을 제공하는 부분에서 문제가 될 가능성이 크다. 일반적으로 정적 파일은 용량이 크기 때문에 컴퓨팅 자원을 많이 소모해서 서버에 과부하가 걸릴 가능성이 크다.
  - 개선 : 이를 해결하기 위해 정적 파일을 제공하는 서버만 별도로 분리하는 구성을 많이 가져간다.
3. 정적 파일 서버 분리
  - 구성 : S3를 활용해 정적 파일만을 제공하는 별도의 서버를 구축했다.
  - 문제점 : 하지만 정적 파일은 용량이 큰 경우가 많기 때문에, 정적 파일을 제공받는 곳이랑 거리가 멀면 멀수록 응답 속도가 오래 걸릴 수 밖에 없다.
  - 개선 : 이를 해결하기 위해 캐싱의 원리가 적용된 CDN을 활용해서 정적 파일 전송 속도를 향상시킨다.
4. CDN 서버 활용
  - 문제점 : 이 구성에서 사용자 요청이 더 많아져서 EC2 인스턴스 한 대로 모든 요청을 처리할 수 없는 상황이 왔다고 가정하자. 이런 경우에는 EC2를 확장해야 한다.
  - 개선 : 확장 방식에는 수직적 확장과 수평적 확장의 방식이 있다는 걸 배웠다. 하지만 시스템 이중화의 장점 때문에 EC2를 확장할 때는 수평적 확장의 방식을 많이 활용한다.
    (수직적 확장도 동시에 적용시키는 경우도 많다.)
5. 웹 애플리케이션 서버의 수평적 확장
  - 구성 : 수평적 확장의 방식으로 웹 애플리케이션 서버(EC2)를 여러 대로 늘렸다.
  - 문제점 : 하지만 사용자보고 여러 서버에 골고루 알아서 요청을 보내라고 시킬 수는 없다.
  - 개선 : 사용자의 요청을 여러 대의 웹 애플리케이션 서버에 골고루 전달하기 위한 장치가 필요하다.   
    그게 바로 로드밸런서(ELB)이다.
6. 로드 밸런서 도입
  - 구성 : 로드 밸런서를 도입함으로써 수평적 확장을 한 여러 대의 EC2에 골고루 트래픽을 분산시킬 수 있게 됐다.
  - 문제점 : 하지만 늘어난 웹 애플리케이션 서버에 따라 많은 수의 요청이 DB에 몰리게 된다.
  - DB에서 병목 현상이 발생하면 DB 자체적으로 성능 개선할 수 있는 부분은 없는 지를 먼저 고려한다. DB 자체적으로 성능 개선하는 방법에는 인덱스 활용, 역정규화, SQL문 튜닝 등이 있다. 이 방식으로 최대한 개선을 했는데도 DB에 병목 현상이 발생할 수도 있다.
  - 개선 : 그러면 수평적 확장의 방식을 고려해봐야 한다. 
    - 문제점 : 하지만 DB에 수평적 확장의 방식을 적용시키는 건 어려운 점이 많다. 왜냐하면 기존에 저장되어 있는 데이터를 수평적 확장한 모든 DB에 복사해서 관리해야 한다. 데이터의 변경이 일어날 때마다 여러 대의 DB가 동기화 작업을 해야 한다. 동기화 작업은 DB 성능 저하를 유발하기 때문에 오히려 장점보다 단점이 더 큰 확장 방식이라고 판단했다.
      - 개선 : 이 때문에 DB는 수평적 확장보다는 수직적 확장의 방식으로 성능을 개선한다. 
        - 개선 : 만약 DB를 최대한으로 수직적 확장을 했음에도 추가적인 성능 개선이 필요하다면 읽기 전용 데이터베이스(Read Repica) 도입을 고려한다.
7. 읽기 전용 데이터베이스(Read Replica) 도입
  - DB를 수평적 확장을 하지 못했던 이유는 데이터의 동기화의 어려움 때문이었다. 하지만 실제 서비스에서 사용하는 쿼리 중 일부는 정밀한 데이터 동기화가 필요 없는 경우가 많다. 따라서 정밀한 데이터 동기화가 필요 없는 쿼리를 실행시킬 때 읽기 전용 데이터베이스(Read Replica)를 많이 활용한다.  
  - 구성 : 원래 하나의 데이터베이스가 모든 트래픽을 처리했어야만 했는데, 읽기 전용 데이터베이스(Read Replica)를 도입함으로써 트래픽을 나눠서 처리할 수 있게 됐다.
  - 개선 : 이와 같은 방식으로 고사양의 데이터베이스를 사용하다보면 문제가 되는 게 비용이다. AWS의 다양한 서비스 중 RDS(데이터베이스)는 비싼 자원에 속한다. 그래서 비용 절감과 성능 향상을 위해 캐시 서버를 많이 활용한다.
8. 캐시 서버 도입
  - 데이터를 조회할 때 항상 DB로 요청을 보냈었다면, 캐시 서버를 도입함으로써 데이터 조회 요청의 응답을 DB 서버와 캐시 서버가 나눠서 처리할 수 있게 된다. 즉, 캐시 서버를 활용해서 DB 부하를 줄일 수 있다.

### 요약
- **EC2(웹 애플리케이션 서버)가 병목 지점일 경우**
  1. 애플리케이션 로직에서 비효율적인 부분 개선하기
  2. 정적 파일 서버(S3, Cloudfront) 분리하기
  3. 로드밸런서(ELB)를 활용해 수평적 확장하기
  4. 수직적 확장하기

- **RDS(데이터베이스 서버)가 병목 지점일 경우**
  1. 비효율적인 쿼리 개선하기 (인덱스 활용, SQL문 튜닝, 역정규화 등)
  2. 수직적 확장하기
  3. 읽기 전용 데이터베이스(Read Replica) 도입하기
  4. 캐시 서버 도입하기

2\. 정리
-------------------------------------
- **개념** : 서버가 어느 정도의 요청을 견딜 수 있는 지 테스트.
- **필요성**
  - “서비스를 오픈하려고 하는데 사용자들이 몰려서 서버가 터지면 어떡하지?”
  - “내 서버는 어느 정도 사용자 요청을 견딜 수 있는 거지?”
  - “개발자님, 이번에 치킨 이벤트를 하려하는데 사용자가 1만명 정도가 들어와도 서버가 괜찮을까요?”
- **목표**
  - **[예시]**
    - **목표 Throughput : 2000TPS** 
      - → 서비스에 예상 접속자 수, 예상 요청 수 등을 활용해 TPS 목표를 설정한다.
    - **평균 Latency : 800ms** 
      - → 서비스의 특성에 맞게 Latency를 설정한다.
- **주의사항**
  - 프로덕션 환경과 비슷한 데이터 셋팅
  - 프로덕션과 분리된 환경에서 테스트하기
- **Throughput** : 서비스가 1초당 처리할 수 있는 트래픽 양
- **TPS(Transaction Per Seconds)** : 1초당 처리한 트랜잭션의 수
  - 참고) TPS(Transaction Per Seconds) ≒ RPS(Request Per Second)
  - ex)  1초에 최대 100개의 API 요청을 처리할 수 있다면, 이 서비스의 **Throughput**은 **100 TPS**라고 얘기한다.
- **Latency** : 요청에 대한 응답 시간
- **모니터링** : 병목 지점을 파악하기 위해서 부하 테스트를 하면서 컴퓨터의 자원(CPU, 메모리 등)을 모니터링(= 어떤 대상을 지속적으로 감시)해야 한다.
- **메트릭(Metric)** : 수치 데이터 또는 측정값을 의미한다. 모니터링을 통해 측정하는 CPU, 메모리 등의 값을 전부 메트릭(Metric)이라고 부른다.
- **CPU** : 계산할때 사용됨(연산작업)
- **메모리** : 변수 공간 저장할때 사용됨
- **가용성(Availability)** : 시스템이 서비스를 정상적으로 제공할 수 있는 가능성
  - 시스템 이중화
- 시스템 성능 개선에 가장 많이 활용하는 3가지 전략
  - 수평적 확장 : 특정 시스템 성능을 올리기 위해 시스템 개수를 늘리는 걸 수평적 확장이라고 한다.
  - 수직적 확장 : 특정 시스템 성능을 올리기 위해 시스템 개수 변경 없이 시스템의 스펙(CPU, 메모리 등)을 업그레이드 하는 방식
  - 캐싱 : 데이터를 더 빠르게 액세스(조회)할 수 있는 곳에 임시로 저장하는 방식
    - CDN(Content Caching&Delivery)
- 병목지점 : 전체 시스템에서 특정 서버 자원(CPU, Memory 등)이 한계에 도달해 전체 성능이 저하되는 구간
  - ’병목 지점의 Throughput’이 곧 ‘전체 Throughput’이다.
  - 특정 병목 지점을 해소하면 다른 곳에서 새로운 병목 지점이 발생한다.
- 툴 :  k6 이외에도 ngrinder, jmeter, ab, locust
  - 여러 명의 사용자를 대신해서 요청을 보내는 툴이다.
  - $ k6 run --vus 30 --duration 10s script.js
    - `--vus 30` : 가상 유저(Virtual Users)를 30명으로 셋팅     
      (API 요청을 보내는 사용자가 30명인 것처럼 부하 생성)
    - `--duration 30s` : 30초 동안 테스트를 유지
- 실시간으로 CPU와 메모리를 관측하는 방법
  - CPU, 메모리를 1초 간격으로 관측하고 싶을 수도 있다. 하지만 CloudWatch는 1분 간격으로만 측정을 하기 때문에 한계가 있다.
  - 리눅스 top 명령어를 사용하면 실시간 관측이 가능하다.
- 주요 지표
  - 시스템의 최대 Throughput을 측정한다.
  - 병목지점 파악 후 개선
  - 개선 후 목표에 도달할때까지 부하테스트 다시 실행